<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Questions</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Oswald:wght@400;700&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@400;700&display=swap" rel="stylesheet">

</head>
<body>
    <header>
        <div class="header-container">
            <img src="logo_processed.png" alt="CS Logo" class="logo">
            <h1>Research Questions</h1>
            <nav>
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="about.html">About</a></li>
                    <li class="dropdown">
                        <a href="javascript:void(0)" class="dropbtn">Explore</a>
                        <div class="dropdown-content">
                            <a href="communication.html">Communicative Practices</a>
                            <a href="participatory.html">Participatory Mechanisms</a>
                            <a href="majortopics.html">Major Topics</a>
                            <a href="research.html">Research Questions</a>
                        </div>
                    </li>
                    <li><a href="references.html">References</a></li>
                </ul>
            </nav>
        </div>
    </header>
    <section class="content-section">
        <h2>Research Questions in Computer Science</h2>
        <p>Computer Science research revolves around addressing significant questions that push the boundaries of technology. Examples of key questions include:</p>
        <ul>
            <li>How can machine learning algorithms be optimized to handle more complex data sets efficiently?</li>
        </ul>
        <div class="indented-paragraph">
            <p>
                Optimizing machine learning algorithms for complex datasets involves techniques like ensemble learning, which improves model accuracy by combining several algorithms. Local learning strategies reduce computational costs by dividing data into smaller clusters for localized analysis, making models more efficient. Semiparametric approximation further helps by balancing bias and variance, allowing algorithms to better handle high-dimensional data without sacrificing performance. These methods are vital for managing the scalability and complexity inherent in large datasets.
            </p>
        </div>
        
        <ul>
            <li>What advancements are being made in quantum computing, and how will they affect current cryptography standards?</li>
        </ul>
        <div class="indented-paragraph">
            <p>
                Quantum computing is set to revolutionize current cryptographic standards, particularly through algorithms like Shor’s and Grover’s. Shor’s algorithm, which efficiently solves large prime factorization problems, threatens public-key cryptography methods like RSA and Elliptic Curve Cryptography (ECC), which rely on these hard mathematical problems. Similarly, Grover’s algorithm provides a quadratic speed-up in searching unsorted databases, posing challenges to symmetric encryption methods like AES, though this threat can be mitigated by using larger key sizes. The future of cryptography lies in developing quantum-resistant methods such as lattice-based and hash-based cryptography.
            </p>
        </div>
        
        <ul>
            <li>What ethical considerations arise with the increasing use of AI in decision-making systems?</li>
        </ul>
        <div class="indented-paragraph">
            <p>
                As AI increasingly powers decision-making systems, ethical concerns arise regarding bias, accountability, transparency, and privacy. AI systems often inherit biases from their training data, leading to unfair outcomes, especially in critical areas such as hiring, law enforcement, and healthcare. The lack of transparency in AI algorithms, commonly referred to as the "black box" problem, makes it difficult to understand how decisions are made. Additionally, the large-scale data collection necessary for AI raises privacy concerns, highlighting the need for regulatory frameworks to ensure fairness, accountability, and transparency.
            </p>
        </div>
        
        
        <div class="research-container">
            <img src="https://i.gifer.com/origin/71/711557abfeed55bc0ebc5185168147c6_w200.gif" alt="Research in Computer Science" class="responsive-img">
            <img src="https://cdn.dribbble.com/users/39753/screenshots/6648190/im-a-computer.gif" alt="Research in Computer Science" class="responsive-img">
        <div>
    </section>

    <footer>
        <p>© 2025 Computer Science Discourse Community</p>
    </footer>
</body>
</html>
